# -*- coding: utf-8 -*-
"""MLT-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LHf8kwYxL5uUqFgPi6eO22vhVODBVrUi

# Import Library
"""

!pip install scikit-surprise

pip install numpy==1.24.3

import numpy as np
import pandas as pd

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Recommendation tools
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import precision_score, recall_score, f1_score

# untuk collaborative filtering)
from surprise import Dataset, Reader, SVD
from surprise.model_selection import cross_validate, train_test_split
from surprise import accuracy
from surprise.accuracy import rmse, mae

# Lainnya
import warnings
warnings.filterwarnings('ignore')

from google.colab import files

"""Pada tahap ini, mengimpor semua library Python yang dibutuhkan untuk proses data, visualisasi, dan pembangunan model sistem rekomendasi, baik content-based maupun collaborative filtering.

# Loading Data
"""

files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d grouplens/movielens-20m-dataset
!unzip -q movielens-20m-dataset.zip -d movielens

movies = pd.read_csv('/content/movielens/movie.csv')
ratings = pd.read_csv('/content/movielens/rating.csv', nrows=500_000)

# Tampilkan 5 data teratas
print("Movies head:")
print(movies.head())

print("\nRatings head:")
print(ratings.head())

"""Dataset MovieLens 20M terdiri dari file movies.csv dan ratings.csv. File movies.csv berisi informasi film (movieId, title, genres), sedangkan ratings.csv berisi interaksi user terhadap film (userId, movieId, rating, timestamp).

# Univariate Exploratory Data Analysis
"""

# Print jumlah data (baris) masing-masing
print(f"\nJumlah data movies: {len(movies)}")
print(f"Jumlah data ratings: {len(ratings)}")

"""Kode ini berfungsi untuk menampilkan jumlah baris (data) yang ada pada masing-masing dataset movies dan ratings. Dengan kata lain, ini membantu untuk mengetahui berapa banyak data film dan rating yang sudah berhasil dimuat ke dalam program."""

# Genres
genre_count = movies['genres'].str.split('|').explode().value_counts()
genre_count.plot(kind='bar', title='Genre Distribution')
plt.ylabel('Jumlah Film')
plt.show()

print("\n")
# Ratings
ratings['rating'].plot(kind='hist', bins=10, title='Rating Distribution')
plt.xlabel('Rating')
plt.show()

"""Di tahap ini kita mengeksplorasi distribusi genre film dan distribusi nilai rating. Ini membantu kita memahami karakteristik data yang akan digunakan dalam model.

# Data Processing
"""

# Cek missing value
print(movies.isnull().sum())
print("\n")
print(ratings.isnull().sum())

"""Melakukan cek missing value pada dataset movie dan rating"""

# Merge ratings dan movies
data = pd.merge(ratings, movies, on='movieId')

"""Menggabungkan file ratings dengan movies berdasarkan movieId"""

# Drop timestamp
data.drop(['timestamp'], axis=1, inplace=True)

"""Menghapus kolom tidak relevan (timestamp)"""

# Hapus duplikat jika ada
data.drop_duplicates(inplace=True)

"""Membersihkan data duplikat atau tidak berguna."""

# Membersihkan data tanpa genre
movies['genres'] = movies['genres'].replace('(no genres listed)', '')

"""Sintaks movies ini digunakan untuk membersihkan data pada kolom genres di DataFrame movies dengan mengganti nilai '(no genres listed)' menjadi string kosong. Ini penting agar data tanpa genre tidak mengganggu proses analisis atau pembuatan model content-based seperti TF-IDF, yang mengandalkan teks dalam kolom tersebut.

# Data Preparation
"""

# TF-IDF untuk Content-Based Filtering
tfidf = TfidfVectorizer(token_pattern=r'[^|]+')
tfidf_matrix = tfidf.fit_transform(movies['genres'])

# Hitung cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Buat mapping judul ke index
indices = pd.Series(movies.index, index=movies['title']).drop_duplicates()

"""Untuk pendekatan Content-Based Filtering, kita menyiapkan TF-IDF berdasarkan genres, menghitung cosine similarity antar film, dan membuat mapping dari judul ke indeks.

# Modelling Content-Based Filtering
"""

def recommend(title, cosine_sim=cosine_sim):
    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]
    movie_indices = [i[0] for i in sim_scores]
    return movies['title'].iloc[movie_indices]

recommend('Toy Story (1995)')

"""Model menghitung kemiripan antar film berdasarkan genre menggunakan TF-IDF dan cosine similarity. Output berupa 10 rekomendasi film yang paling mirip dengan input.

# Modelling Collaborative Filtering
"""

# Format data untuk Surprise
reader = Reader(rating_scale=(0.5, 5.0))
data_cf = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)

# Split data menjadi train dan test (80% train, 20% test)
trainset, testset = train_test_split(data_cf, test_size=0.2, random_state=42)

# Gunakan model SVD
model = SVD()

# Training model dengan data train
model.fit(trainset)

"""Kode ini menyiapkan data rating untuk model Collaborative Filtering dengan Surprise, membagi data menjadi train dan test, lalu melatih model SVD menggunakan data train untuk memprediksi preferensi pengguna terhadap film.

# Evaluasi

### Content-Based Filtering
"""

print(recommend('Money Train (1995)'))

"""Evaluasi dilakukan secara kualitatif dengan melihat apakah film-film yang direkomendasikan relevan dengan film input."""

# Tentukan threshold untuk similarity agar dianggap "relevan"
threshold = 0.3

# Fungsi untuk evaluasi Content-Based Filtering
def evaluate_content_based(cosine_sim, top_n=10, threshold=0.3):
    precisions = []
    recalls = []
    f1s = []

    n_movies = cosine_sim.shape[0]

    for idx in range(n_movies):
        # Ground truth biner: film yang similarity-nya >= threshold
        true_labels = (cosine_sim[idx] >= threshold).astype(int)
        true_labels[idx] = 0  # exclude self similarity

        # Prediksi biner: top-N film paling mirip
        sim_scores = list(enumerate(cosine_sim[idx]))
        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
        top_n_indices = [i[0] for i in sim_scores[1:top_n+1]]  # exclude self

        pred_labels = np.zeros(n_movies, dtype=int)
        pred_labels[top_n_indices] = 1

        # Hitung metrik
        precision = precision_score(true_labels, pred_labels)
        recall = recall_score(true_labels, pred_labels)
        f1 = f1_score(true_labels, pred_labels)

        precisions.append(precision)
        recalls.append(recall)
        f1s.append(f1)

    print(f'Average Precision: {np.mean(precisions):.4f}')
    print(f'Average Recall: {np.mean(recalls):.4f}')
    print(f'Average F1-Score: {np.mean(f1s):.4f}')


# Jalankan evaluasi
evaluate_content_based(cosine_sim, top_n=10, threshold=0.3)

"""Evaluasi dilakukan dengan menghitung metrik Precision, Recall, dan F1-Score.
Kita menggunakan threshold pada nilai cosine similarity untuk membuat ground truth biner film yang dianggap relevan (mirip).
Selanjutnya, kita bandingkan dengan prediksi biner yang dihasilkan dari top-N rekomendasi untuk menghitung ketiga metrik tersebut secara rata-rata.
Metrik ini membantu menilai seberapa baik model merekomendasikan film yang benar-benar relevan.

### Collaborative Filtering
"""

# Prediksi rating pada data test
predictions = model.test(testset)

# Hitung metrik evaluasi RMSE dan MAE
rmse = accuracy.rmse(predictions)
mae = accuracy.mae(predictions)

"""Model dievaluasi menggunakan metrik RMSE dan MAE untuk mengukur seberapa dekat prediksi rating dengan rating asli pengguna pada data test."""

metrics = ['RMSE', 'MAE']
values = [rmse, mae]

plt.figure(figsize=(6, 4))
bars = plt.bar(metrics, values, color=['skyblue', 'salmon'])
plt.title('Evaluation Metrics - Collaborative Filtering (SVD)')
plt.ylabel('Error')

# Tambahkan nilai di atas bar
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f'{yval:.3f}', ha='center', va='bottom')

plt.ylim(0, max(values) + 0.5)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Visualisasi ini menunjukkan performa model SVD berdasarkan metrik RMSE dan MAE. Kedua metrik digunakan untuk mengukur akurasi prediksi rating, di mana nilai yang lebih rendah menunjukkan hasil yang lebih baik.

# inference

menghasilkan rekomendasi Top-N berdasarkan hasil model Collaborative Filtering (SVD) yang sudah dilatih sebelumnya.
"""

from collections import defaultdict

def get_top_n(predictions, n=10):
    top_n = defaultdict(list)
    for uid, iid, true_r, est, _ in predictions:
        top_n[uid].append((iid, est))
    for uid, user_ratings in top_n.items():
        user_ratings.sort(key=lambda x: x[1], reverse=True)
        top_n[uid] = user_ratings[:n]
    return top_n

top_n = get_top_n(predictions, n=10)

"""Fungsi get_top_n mengelompokkan prediksi rating berdasarkan user, lalu mengurutkan dan memilih top-N rekomendasi dengan rating tertinggi untuk setiap user."""

# Menampilkan 2 pengguna pertama saja
for i, (uid, user_ratings) in enumerate(top_n.items()):
    print(f"User {uid} Top-{len(user_ratings)} recommendations:")
    for movie_id, predicted_rating in user_ratings:
        print(f"  MovieID: {movie_id}, Predicted Rating: {predicted_rating:.2f}")
    print("="*40)
    if i == 1:
        break

"""Menampilkan rekomendasi top-N untuk dua user pertama, mencetak movie ID dan prediksi ratingnya secara singkat."""

movie_id_to_title = dict(zip(movies['movieId'], movies['title']))

# menampilkan rekomendasi lengkap dengan judul film
for uid, user_ratings in top_n.items():
    print(f"User {uid} Top-{len(user_ratings)} recommendations:")
    for movie_id, predicted_rating in user_ratings:
        title = movie_id_to_title.get(movie_id, "Unknown Title")
        print(f"  {title} (MovieID: {movie_id}) - Predicted Rating: {predicted_rating:.2f}")
    print("="*40)
    break

"""Membuat mapping dari movieId ke judul film, lalu menampilkan rekomendasi untuk satu user dengan judul film lengkap beserta prediksi ratingnya."""